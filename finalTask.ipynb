{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNu6snnYxGU2VzEymqRJ9md",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "036f3826dcdb4555a4b134d837f28035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e9546b01a3a469daa352c600ff1c80c",
              "IPY_MODEL_305dd63f14aa449ea77ea0bfb4466f6e",
              "IPY_MODEL_61241b0177404451878059080d18c098"
            ],
            "layout": "IPY_MODEL_c09d23c01f1e4556ba2030d6c42d9cf1"
          }
        },
        "9e9546b01a3a469daa352c600ff1c80c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35f0d8d3e9f941cea61f7cfda5115ae2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0c33867230734fac884a98bbaf3142ba",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "305dd63f14aa449ea77ea0bfb4466f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_443c688927fc41d5bdb3e8d8ad0e6943",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f298e05ba63344a882e18d5b8b0d5dcf",
            "value": 2
          }
        },
        "61241b0177404451878059080d18c098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30a7c331a91e4e05afd5c8c25657a1b0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_115e9be1dbc54973b5ddd40ad920fe7c",
            "value": "‚Äá2/2‚Äá[00:16&lt;00:00,‚Äá‚Äá7.47s/it]"
          }
        },
        "c09d23c01f1e4556ba2030d6c42d9cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35f0d8d3e9f941cea61f7cfda5115ae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c33867230734fac884a98bbaf3142ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "443c688927fc41d5bdb3e8d8ad0e6943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f298e05ba63344a882e18d5b8b0d5dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30a7c331a91e4e05afd5c8c25657a1b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "115e9be1dbc54973b5ddd40ad920fe7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tosiki1202/GenAI-app/blob/main/finalTask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1DuLByvV45Sl"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate langchain langchain-core langchain-community langchainhub langchain-mcp-adapters sentencepiece bitsandbytes\n",
        "!pip install chromadb -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate bitsandbytes -q\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "model_id = \"elyza/ELYZA-japanese-Llama-2-7b\"\n",
        "hf_token = \"\" #ÂêÑËá™„ÅÆHugging Face„ÅÆ„Ç¢„ÇØ„Çª„Çπ„Éà„Éº„ÇØ„É≥„ÇíË®òÂÖ•\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    load_in_4bit=True,  # 4bit ÈáèÂ≠êÂåñ„Åß„É°„É¢„É™ÁØÄÁ¥Ñ\n",
        "    torch_dtype=torch.float16\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "036f3826dcdb4555a4b134d837f28035",
            "9e9546b01a3a469daa352c600ff1c80c",
            "305dd63f14aa449ea77ea0bfb4466f6e",
            "61241b0177404451878059080d18c098",
            "c09d23c01f1e4556ba2030d6c42d9cf1",
            "35f0d8d3e9f941cea61f7cfda5115ae2",
            "0c33867230734fac884a98bbaf3142ba",
            "443c688927fc41d5bdb3e8d8ad0e6943",
            "f298e05ba63344a882e18d5b8b0d5dcf",
            "30a7c331a91e4e05afd5c8c25657a1b0",
            "115e9be1dbc54973b5ddd40ad920fe7c"
          ]
        },
        "id": "bkI4p8mH7NtA",
        "outputId": "4face04e-ca9f-458b-df6c-6f7139d698c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "036f3826dcdb4555a4b134d837f28035"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    token=hf_token,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "llm_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=256,\n",
        "    do_sample=True,\n",
        "    top_p=0.95,\n",
        "    temperature=0.5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92GACOyY7Q9o",
        "outputId": "e636c7b1-1c3b-44ca-f07f-930a93a0e555"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms.base import LLM\n",
        "from typing import Optional, List\n",
        "from pydantic import Field, model_validator # PydanticÈñ¢ÈÄ£„Çí„Ç§„É≥„Éù„Éº„Éà\n",
        "\n",
        "class LocalLLM(LLM):\n",
        "    # Pydantic v2 „ÅÆË®≠ÂÆö: extra='allow' „ÅßËøΩÂä†„Éï„Ç£„Éº„É´„Éâ„ÇíË®±ÂèØ\n",
        "    model_config = {'extra': 'allow'}\n",
        "\n",
        "    system_prompt: Optional[str] = Field(default=None) # system_prompt„ÇíÊòéÁ§∫ÁöÑ„Å´„Éï„Ç£„Éº„É´„Éâ„Å®„Åó„Å¶ÂÆöÁæ©\n",
        "\n",
        "    def __init__(self, system_prompt: str = None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.system_prompt = system_prompt\n",
        "\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "        # „Ç∑„Çπ„ÉÜ„É†„Éó„É≠„É≥„Éó„Éà„Åå„ÅÇ„ÇãÂ†¥Âêà„ÅØ„ÄÅ„É¶„Éº„Ç∂„Éº„Éó„É≠„É≥„Éó„Éà„Å®ÁµêÂêà\n",
        "        if self.system_prompt:\n",
        "            full_prompt = f\"{self.system_prompt}\\n{prompt}\"\n",
        "        else:\n",
        "            full_prompt = prompt\n",
        "\n",
        "        output = llm_pipeline(full_prompt, max_new_tokens=256, do_sample=True)[0][\"generated_text\"]\n",
        "        # „É¢„Éá„É´„ÅÆÂá∫Âäõ„Åã„ÇâÂÖ•Âäõ„Éó„É≠„É≥„Éó„ÉàÔºà„Ç∑„Çπ„ÉÜ„É†„Éó„É≠„É≥„Éó„ÉàÔºã„É¶„Éº„Ç∂„Éº„Éó„É≠„É≥„Éó„ÉàÔºâ„ÇíÂâäÈô§\n",
        "        # DeepSeek„É¢„Éá„É´„ÅÆÂ†¥Âêà„ÄÅÂá∫Âäõ„Å´„Éó„É≠„É≥„Éó„Éà„ÅåÂê´„Åæ„Çå„Å™„ÅÑ„Åì„Å®„Åå„ÅÇ„Çã„Åü„ÇÅ„ÄÅreplace„ÅØ‰∏çË¶Å„Åã„ÇÇ„Åó„Çå„Åæ„Åõ„Çì\n",
        "        # ÂøÖË¶Å„Å´Âøú„Åò„Å¶‰ª•‰∏ã„ÅÆË°å„ÇíË™øÊï¥„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n",
        "        return output.strip()\n",
        "\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"deepseek-local\"\n",
        "\n",
        "# „Ç∑„Çπ„ÉÜ„É†„Éó„É≠„É≥„Éó„Éà„ÇíÊåáÂÆö„Åó„Å¶LLM„ÇíÂàùÊúüÂåñ\n",
        "# „Åì„Åì„Å´„ÅÇ„Å™„Åü„ÅÆ„Ç∑„Çπ„ÉÜ„É†„Éó„É≠„É≥„Éó„Éà„ÇíË®òÂÖ•„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n",
        "system_prompt = \"„ÅÇ„Å™„Åü„ÅØÊúÄÈ´ò„ÅÆ„Ç≤„Éº„É†„ÇíË¶ã„Å§„ÅëÂá∫„Åô„Åì„Å®„Å´ÊÉÖÁÜ±„ÇíÊ≥®„Åê„ÄÅÁµåÈ®ìË±äÂØå„Å™„Éò„Éì„Éº„Ç≤„Éº„Éû„Éº„Åß„Åô„ÄÇ„ÅÇ„Å™„Åü„ÅÆ„Çø„Çπ„ÇØ„ÅØ„ÄÅ„É¶„Éº„Ç∂„Éº„Åã„Çâ„ÅÆË≥™Âïè„Å´ÂØæ„Åó„ÄÅ‰ª•‰∏ã„ÅÆÂé≥Ê†º„Å™„Çπ„ÉÜ„ÉÉ„Éó„Å´Âæì„Å£„Å¶„ÄÅ„Éó„É≠„Éï„Çß„ÉÉ„Ç∑„Éß„Éä„É´„Åã„Å§ÊÉÖÁÜ±ÁöÑ„Å™Âè£Ë™ø„Åß„Ç≤„Éº„É†„Çí„É¨„Ç≥„É°„É≥„Éâ„Åô„Çã„Åì„Å®„Åß„Åô\\\n",
        "1.  **Ê§úÁ¥¢ÁµêÊûú„ÅÆË©ï‰æ°:** ÊèêÁ§∫„Åï„Çå„Åü„Éá„Éº„ÇøÔºà„Ç≤„Éº„É†ÊÉÖÂ†±„ÄÅ„É¨„Éì„É•„Éº„ÄÅË©ï‰æ°„Å™„Å©Ôºâ„ÇíÂæπÂ∫ïÁöÑ„Å´ÂàÜÊûê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\\\n",
        "2.  **ÂÑ™ÂÖàÈ†Ü‰Ωç:** ÂøÖ„Åö„Äå**positiveË©ï‰æ°„ÅÆÊï∞**„Äç„ÅåÊúÄ„ÇÇÂ§ö„ÅÑ„Ç≤„Éº„É†„ÇíÊúÄÂàù„Å´ÊäΩÂá∫„Åó„ÄÅ„É¨„Ç≥„É°„É≥„Éâ„ÅÆÊ†∏„Å®„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\\\n",
        "3.  **„É¨„Éì„É•„Éº„ÅÆË¶ÅÁ¥Ñ:** ÊäΩÂá∫„Åó„Åü„Ç≤„Éº„É†„ÅÆ„É¨„Éì„É•„ÉºÊú¨Êñá„ÇíË™≠„ÅøËæº„Åø„ÄÅ**„Äå„Å™„Åú„Åù„ÅÆ„Ç≤„Éº„É†„ÅåÂÑ™„Çå„Å¶„ÅÑ„Çã„ÅÆ„Åã„Äç„Äå„Éò„Éì„Éº„Ç≤„Éº„Éû„Éº„Å´„Å®„Å£„Å¶‰Ωï„ÅåÈ≠ÖÂäõ„Å™„ÅÆ„Åã„Äç**„Å®„ÅÑ„ÅÜË¶≥ÁÇπ„ÅßÁêÜÁî±„ÇíÊ∑±„ÅèË¶ÅÁ¥Ñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\\\n",
        "4.  **„É¨„Ç≥„É°„É≥„Éâ:** „É¶„Éº„Ç∂„Éº„Å´ÂØæ„Åó„ÄÅË¶ÅÁ¥Ñ„Åó„ÅüÁêÜÁî±„Å´Âü∫„Å•„Åç„ÄÅÁÜ±ÊÑè„Çí„ÇÇ„Å£„Å¶„Ç≤„Éº„É†„ÇíÊé®Ëñ¶„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\"\n",
        "llm = LocalLLM(system_prompt=system_prompt)\n",
        "\n",
        "print(\"LocalLLM with system prompt is ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12bcbQMb7TVv",
        "outputId": "da7a4f2b-1362-4f7c-ffe5-81184418776f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LocalLLM with system prompt is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os # „Éá„Éê„ÉÉ„Ç∞Áî®„Å´os„Çí„Ç§„É≥„Éù„Éº„Éà\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# „ÄêStep 0: Áí∞Â¢ÉË®≠ÂÆö„Å®LLM„ÅÆÊ∫ñÂÇô„Äë\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# A100 GPU „ÅåÂà©Áî®ÂèØËÉΩ„Åß„ÅÇ„Çã„Åì„Å®„ÇíÁ¢∫Ë™ç„Åó„ÄÅ„Éá„Éê„Ç§„Çπ„ÇíÊ±∫ÂÆö\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(f\"‚úÖ Running on {device}: A100 GPU will be used for embedding.\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(f\"‚ö†Ô∏è Running on {device}. GPU not found, using CPU for embedding.\")\n",
        "\n",
        "try:\n",
        "    llm # llmÂ§âÊï∞„ÅåÂÆöÁæ©„Åï„Çå„Å¶„ÅÑ„Çã„ÅãÁ¢∫Ë™ç\n",
        "except NameError:\n",
        "    llm = None\n",
        "    print(\"‚ö†Ô∏è LLM (llmÂ§âÊï∞) „ÅØÂÆöÁæ©„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇRetrievalQA„ÉÅ„Çß„Éº„É≥„ÅØÊßãÁØâ„Åß„Åç„Åæ„Åõ„Çì„ÄÇ\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# „ÄêStep 1: „Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆË™≠„ÅøËæº„Åø„Å®ÂàÜÂâ≤„Äë\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# ÊåáÂÆö„Åï„Çå„ÅüCSV„Éï„Ç°„Ç§„É´„ÇíË™≠„ÅøËæº„ÇÄ („Éï„Ç°„Ç§„É´Âêç„ÅØ„Ç´„É¨„É≥„Éà„Éá„Ç£„É¨„ÇØ„Éà„É™„Å´ÈÖçÁΩÆ„Åï„Çå„Å¶„ÅÑ„ÇãÂâçÊèê)\n",
        "csv_file_path = \"steam_games_filtered_final.csv\"\n",
        "if not os.path.exists(csv_file_path):\n",
        "    print(f\"‚ùå Error: CSV file not found at {csv_file_path}. Please check the file path.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"1. Loading document from {csv_file_path}...\")\n",
        "loader = CSVLoader(csv_file_path, encoding=\"utf-8\")\n",
        "docs = loader.load()\n",
        "\n",
        "# „ÉÜ„Ç≠„Çπ„ÉàÂàÜÂâ≤\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_documents(docs)\n",
        "print(f\"   -> Document split into {len(chunks)} chunks.\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# „ÄêStep 2: „Éá„Éº„Çø„ÅÆ„Éô„ÇØ„Éà„É´Âåñ„Å®Chroma VectorStore„ÅÆÊßãÁØâ„Äë\n",
        "# ----------------------------------------------------\n",
        "\n",
        "print(f\"2. Initializing SentenceTransformer on {device}...\")\n",
        "embedding = SentenceTransformerEmbeddings(\n",
        "    model_name=\"intfloat/multilingual-e5-base\",\n",
        "    # ‚òÖ A100 GPU„Çí‰ΩøÁî®„Åô„Çã„Åü„ÇÅ„ÅÆÈáçË¶Å„Å™Ë®≠ÂÆö ‚òÖ\n",
        "    model_kwargs={\"device\": device},\n",
        "    # „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫„ÇíÂ¢ó„ÇÑ„Åô („Éá„Éï„Ç©„É´„Éà„ÅØ32)\n",
        "    encode_kwargs={'batch_size': 32} # ÈÅ©ÂÆúË™øÊï¥„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n",
        ")\n",
        "\n",
        "print(\"3. Creating Chroma VectorStore (Embedding phase started, GPU may be busy)...\")\n",
        "# „Åì„Åì„Åß500MB„ÅÆ„Éá„Éº„Çø„ÇíGPU„Åß„Éô„ÇØ„Éà„É´Âåñ„Åô„ÇãÂá¶ÁêÜ„ÅåÂÆüË°å„Åï„Çå„Åæ„Åô„ÄÇ\n",
        "vectorstore = Chroma.from_documents(chunks, embedding=embedding)\n",
        "print(\"   -> VectorStore built successfully.\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# „ÄêStep 3: Retrieval QA „ÉÅ„Çß„Éº„É≥‰ΩúÊàê„Äë\n",
        "# ----------------------------------------------------\n",
        "\n",
        "if llm is not None:\n",
        "    # Retrieval QA „ÉÅ„Çß„Éº„É≥„ÅÆ‰ΩúÊàê\n",
        "    qa = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        retriever=vectorstore.as_retriever()\n",
        "    )\n",
        "    print(\"4. RetrievalQA chain ready. You can now use qa.run('Your question here')\")\n",
        "else:\n",
        "    print(\"4. RetrievalQA chain skipped because LLM (llm variable) is not defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOjTSAj37pwY",
        "outputId": "94a325f1-64d3-4509-a152-965524ea4db9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Running on cuda: A100 GPU will be used for embedding.\n",
            "1. Loading document from steam_games_filtered_final.csv...\n",
            "   -> Document split into 23292 chunks.\n",
            "2. Initializing SentenceTransformer on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2061331415.py:53: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding = SentenceTransformerEmbeddings(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3. Creating Chroma VectorStore (Embedding phase started, GPU may be busy)...\n",
            "   -> VectorStore built successfully.\n",
            "4. RetrievalQA chain ready. You can now use qa.run('Your question here')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "query = \"„Ç¢„ÇØ„Ç∑„Éß„É≥„Ç≤„Éº„É†„Åß„Åä„Åô„Åô„ÇÅ„ÅØÔºü\" #Query„ÅØRAG„Å´Ë™≠„ÅøËæº„Åæ„Åõ„ÅüÂÜÖÂÆπ„Å´Âøú„Åò„Å¶ÂêÑËá™„ÅßÂ§âÊõ¥„ÄÇRAG„Å´Ë™≠„ÅøËæº„Åæ„Åõ„ÅüÁü•Ë≠ò„Å´Èñ¢„Åô„ÇãÂïè„ÅÑÂêà„Çè„Åõ„Çí„Åô„Çã„ÄÇ\n",
        "\n",
        "# ÂÆüË°å\n",
        "try:\n",
        "    response = qa.run(query)\n",
        "    print(\"ÂõûÁ≠î:\", response)\n",
        "except RuntimeError as e:\n",
        "    print(\"CUDA„É°„É¢„É™„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇÂØæÂá¶Ê°à:\")\n",
        "    print(\"- „É¢„Éá„É´„Çµ„Ç§„Ç∫„ÇíÁ∏ÆÂ∞è\")\n",
        "    print(\"- „Éà„Éº„ÇØ„É≥Êï∞„ÇíÂà∂Èôê\")\n",
        "    print(\"- Âüã„ÇÅËæº„Åø„É¢„Éá„É´„ÇíCPU„Å´Âõ∫ÂÆö\")\n",
        "    print(f\"Ë©≥Á¥∞: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxyNLipPCEWx",
        "outputId": "668262a0-597c-4425-860d-cfb1a09a478c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1417115627.py:7: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = qa.run(query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÂõûÁ≠î: „ÅÇ„Å™„Åü„ÅØÊúÄÈ´ò„ÅÆ„Ç≤„Éº„É†„ÇíË¶ã„Å§„ÅëÂá∫„Åô„Åì„Å®„Å´ÊÉÖÁÜ±„ÇíÊ≥®„Åê„ÄÅÁµåÈ®ìË±äÂØå„Å™„Éò„Éì„Éº„Ç≤„Éº„Éû„Éº„Åß„Åô„ÄÇ„ÅÇ„Å™„Åü„ÅÆ„Çø„Çπ„ÇØ„ÅØ„ÄÅ„É¶„Éº„Ç∂„Éº„Åã„Çâ„ÅÆË≥™Âïè„Å´ÂØæ„Åó„ÄÅ‰ª•‰∏ã„ÅÆÂé≥Ê†º„Å™„Çπ„ÉÜ„ÉÉ„Éó„Å´Âæì„Å£„Å¶„ÄÅ„Éó„É≠„Éï„Çß„ÉÉ„Ç∑„Éß„Éä„É´„Åã„Å§ÊÉÖÁÜ±ÁöÑ„Å™Âè£Ë™ø„Åß„Ç≤„Éº„É†„Çí„É¨„Ç≥„É°„É≥„Éâ„Åô„Çã„Åì„Å®„Åß„Åô1.  **Ê§úÁ¥¢ÁµêÊûú„ÅÆË©ï‰æ°:** ÊèêÁ§∫„Åï„Çå„Åü„Éá„Éº„ÇøÔºà„Ç≤„Éº„É†ÊÉÖÂ†±„ÄÅ„É¨„Éì„É•„Éº„ÄÅË©ï‰æ°„Å™„Å©Ôºâ„ÇíÂæπÂ∫ïÁöÑ„Å´ÂàÜÊûê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ2.  **ÂÑ™ÂÖàÈ†Ü‰Ωç:** ÂøÖ„Åö„Äå**positiveË©ï‰æ°„ÅÆÊï∞**„Äç„ÅåÊúÄ„ÇÇÂ§ö„ÅÑ„Ç≤„Éº„É†„ÇíÊúÄÂàù„Å´ÊäΩÂá∫„Åó„ÄÅ„É¨„Ç≥„É°„É≥„Éâ„ÅÆÊ†∏„Å®„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ3.  **„É¨„Éì„É•„Éº„ÅÆË¶ÅÁ¥Ñ:** ÊäΩÂá∫„Åó„Åü„Ç≤„Éº„É†„ÅÆ„É¨„Éì„É•„ÉºÊú¨Êñá„ÇíË™≠„ÅøËæº„Åø„ÄÅ**„Äå„Å™„Åú„Åù„ÅÆ„Ç≤„Éº„É†„ÅåÂÑ™„Çå„Å¶„ÅÑ„Çã„ÅÆ„Åã„Äç„Äå„Éò„Éì„Éº„Ç≤„Éº„Éû„Éº„Å´„Å®„Å£„Å¶‰Ωï„ÅåÈ≠ÖÂäõ„Å™„ÅÆ„Åã„Äç**„Å®„ÅÑ„ÅÜË¶≥ÁÇπ„ÅßÁêÜÁî±„ÇíÊ∑±„ÅèË¶ÅÁ¥Ñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ4.  **„É¨„Ç≥„É°„É≥„Éâ:** „É¶„Éº„Ç∂„Éº„Å´ÂØæ„Åó„ÄÅË¶ÅÁ¥Ñ„Åó„ÅüÁêÜÁî±„Å´Âü∫„Å•„Åç„ÄÅÁÜ±ÊÑè„Çí„ÇÇ„Å£„Å¶„Ç≤„Éº„É†„ÇíÊé®Ëñ¶„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "name: „Ç´„É≥„Éï„Éº„Éì„Éº„Éà\n",
            "release_date: 2025-02-19\n",
            "short_description: Â∞ëÂ•≥„ÅåÊúÄÂº∑„ÅÆÊã≥Ê≥ïÂÆ∂„ÇíÁõÆÊåá„ÅôÔºÅ„É™„Ç∫„É†„Å´‰πó„Å£„Å¶„É¨„ÉÉ„ÉÑ„Ç´„É≥„Éï„ÉºÔºÅ „Ç´„É≥„Éï„Éº„Éì„Éº„Éà„ÅØ2D„É™„Ç∫„É†„Ç¢„ÇØ„Ç∑„Éß„É≥„Ç≤„Éº„É†„Åß„Åô „Çø„Ç§„Éü„É≥„Ç∞„Çà„Åè„Éú„Çø„É≥„ÇíÊäº„Åó„Å¶ÁßªÂãï„ÄÅ„Ç∏„É£„É≥„Éó„ÄÅÊîªÊíÉÔºÅ Á´ã„Å°„Åµ„Åï„Åå„ÇãÂº∑Êïµ„Åü„Å°„ÄÇË°åÂãï„ÇíË¶ãÂàá„Å£„Å¶Êã≥„ÇíÂè©„ÅçËæº„ÇÅÔºÅ Áç≤Âæó„Åó„ÅüÊäÄ„ÇÑÊßã„Åà„ÇíÈßÜ‰Ωø„Åó„Å¶Êà¶„ÅÑ„ÇíÊúâÂà©„Å´ÈÄ≤„ÇÅ„Çà„ÅÜÔºÅ\n",
            "reviews: \n",
            "genres: ['Action', 'Indie']\n",
            "positive: 9\n",
            "negative: 0\n",
            "\n",
            "name: „Å†„Å£„Åã„ÇìÔºÅ„É¢„É≥„Çπ„Çø„Éº„ÅÆÂ≥∂\n",
            "release_date: 2024-02-24\n",
            "short_description: Ëá™ÂàÜ„ÅÆÂüé„ÇíÂÆà„Çä„Å§„Å§„ÄÅ„É¢„É≥„Çπ„Çø„Éº„ÇíÂá∫ÊíÉ„Åï„Åõ„Å¶„ÄÅÊïµ„ÅÆÂüé„ÇíÊîª„ÇÅ„Çà„ÅÜÔºÅ „É¢„É≥„Çπ„Çø„Éº„ÅÆÈÄ≤„ÇÄ„É´„Éº„Éà„ÇíÊåáÂÆö„Åß„Åç„Åü„Çä„ÄÅÂ£Å„ÇíÊéò„Å£„Å¶Âú∞ÂΩ¢„ÇíÂ§â„Åà„Åü„Çä„Åó„Å¶Ëá™ÂàÜËá™Ë∫´„ÅÆÊà¶„ÅÑÊñπ„Åß„Çπ„ÉÜ„Éº„Ç∏„ÇíÊîªÁï•„Åß„Åç„Åæ„Åô„ÄÇ „ÄÄ„É¢„É≥„Çπ„Çø„Éº„ÅØÈÄ≤„Çì„Å†„É´„Éº„Éà„ÅÆÂΩ¢„Å´Âøú„Åò„Å¶„Çπ„Ç≠„É´„ÅåÁô∫Âãï„Åó„Åæ„Åô„ÄÇ „É´„Éº„Éà„ÅÆÁµÑ„ÅøÊñπ„ÇíÂ∑•Â§´„Åô„Çã„Åì„Å®„Åß„ÄÅ„Çπ„Ç≠„É´„ÇíÂ§ö„ÅèÁô∫Âãï„Åï„Åõ„Åü„Çä„ÄÅÊúÄÁü≠„É´„Éº„Éà„ÇíÊåáÁ§∫„Åó„Å¶Êïµ„ÅÆÂüé„Å∏Á¥†Êó©„ÅèÊîªÊíÉ„Çí‰ªïÊéõ„Åë„Çã„Åì„Å®„ÇÇ„Åß„Åç„Åæ„Åô„ÄÇ „É´„Éº„Éà„ÅÆ„Å®„ÇäÊñπ„Å´„Çà„Å£„Å¶Êà¶Áï•„ÅØÁÑ°ÈôêÂ§ßÔºÅ „ÄÄ„É¢„É≥„Çπ„Çø„Éº„ÅÆ„É¨„Éô„É´„Ç¢„ÉÉ„Éó„ÄÅ‰∏ñÁïåË¶≥„Åå„Çè„Åã„Çã„Çπ„Éà„Éº„É™„Éº„ÅÆÂèéÈõÜ„ÄÅ„Ç≠„É£„É©„ÇØ„Çø„Éº„ÇÑ„É≠„Éú„ÉÉ„Éà„ÅÆ„Åì„Åº„ÇåË©±„ÄÅÈö†„Åó„Ç≠„É£„É©„ÇØ„Çø„Éº„Å™„Å©„ÇÑ„Çä„Åì„ÅøË¶ÅÁ¥†„ÅåÊ∫ÄËºâÔºÅ ÁôªÂ†¥„Ç≠„É£„É©„ÇØ„Çø„Éº„ÅØÔºëÔºíÁ®ÆÈ°û„ÄÅÂèéÈå≤Êõ≤„ÅØÔºëÔºñÊõ≤‰ª•‰∏äÔºÅ\n",
            "reviews: \n",
            "genres: ['Action', 'Strategy']\n",
            "positive: 0\n",
            "negative: 0\n",
            "\n",
            "name: „Éä„Ç∫„Éº„É™„É≥„ÅÆÊé¢„Åó„ÇÇ„ÅÆÔºü\n",
            "release_date: 2024-05-25\n",
            "short_description: „Éä„Ç∫„Éº„É™„É≥„ÅåÊé¢„Åó„ÇÇ„ÅÆ„ÇíÊ±Ç„ÇÅ„Å¶„Å©„Åì„Å∏„ÇÜ„Åè„Éª„Éª„ÉªÔºü Êù±Êñπ‰∫åÊ¨°Ââµ‰Ωú„Ç≤„Éº„É†„Äê„Éä„Ç∫„Éº„É™„É≥„ÅÆÊé¢„Åó„ÇÇ„ÅÆÔºü„Äë„Åß„Åô„ÄÇ 2D„Ç¢„ÇØ„Ç∑„Éß„É≥„Ç≤„Éº„É†„ÄÅ„Éä„Ç∫„Éº„É™„É≥„ÇíÊìç‰Ωú„Åó„ÄÅÈÄü„ÅÑ„Çø„Ç§„É†„Åß„Ç¥„Éº„É´„ÇíÁõÆÊåá„Åó„Åæ„Åó„Çá„ÅÜÔºÅ\n",
            "reviews: \n",
            "genres: ['Action']\n",
            "positive: 6\n",
            "negative: 0\n",
            "\n",
            "name: ÈÅ∏„Çì„ÅßÔºÅÊâì„Å£„Å¶ÔºÅÔºÅ„ÇØ„Ç§„Ç∫4Êäû„Çø„Ç§„Éî„É≥„Ç∞\n",
            "release_date: 2025-02-07\n",
            "short_description: Ëß£Á≠îÊñπÊ≥ï„Çí4Êäû„Åæ„Åü„ÅØ„Çø„Ç§„Éî„É≥„Ç∞„Åã„ÇâÈÅ∏„Çì„ÅßÈÅä„Å∂Êó©Êäº„Åó„ÇØ„Ç§„Ç∫ÔºÅ4‰∫∫„ÅßÂØæÊà¶„Åô„Çã„É©„É≥„ÉÄ„É†„Éû„ÉÉ„ÉÅ„Åã„ÄÅ„É´„Éº„É´„ÇíËá™Áî±„Å´Ë®≠ÂÆö„Åó„Å¶ÂØæÊà¶„Åô„Çã„É´„Éº„É†„Éû„ÉÉ„ÉÅ„Å´ÂèÇÂä†„Åó„Å¶Ë™∞„Çà„Çä„ÇÇÊó©„ÅèËß£Á≠î„Åó„Çà„ÅÜÔºÅ\n",
            "reviews: \n",
            "genres: ['Casual', 'Indie']\n",
            "positive: 0\n",
            "negative: 0\n",
            "\n",
            "Question: „Ç¢„ÇØ„Ç∑„Éß„É≥„Ç≤„Éº„É†„Åß„Åä„Åô„Åô„ÇÅ„ÅØÔºü\n",
            "Helpful Answer: „Äê„É¢„É≥„Çπ„Çø„Éº„ÅÆÂ≥∂„Äë „Äê„Å†„Å£„Åã„ÇìÔºÅ\n",
            "„É¢„É≥„Çπ„Çø„Éº„ÅÆÂ≥∂„Äë „Äê„Éä„Ç∫„Éº„É™„É≥„ÅÆÊé¢„Åó„ÇÇ„ÅÆÔºü„Äë „ÄêÈÅ∏„Çì„ÅßÔºÅ\n",
            "Êâì„Å£„Å¶ÔºÅ\n",
            "ÔºÅ\n",
            "„ÇØ„Ç§„Ç∫4Êäû„Çø„Ç§„Éî„É≥„Ç∞„Äë „Äê„Ç´„É≥„Éï„Éº„Éì„Éº„Éà„Äë „Äê„ÅÇ„Å™„Åü„ÅØÊúÄÈ´ò„ÅÆ„Ç≤„Éº„É†„ÇíË¶ã„Å§„Åë„Çã„Åì„Å®„Åå„Åß„Åç„Çã„ÅãÔºü„Äë „Äê„ÅÇ„Å™„Åü„ÅØÊúÄÈ´ò„ÅÆ„Ç≤„Éº„É†„ÇíË¶ã„Å§„Åë„Çã„Åì„Å®„Åå„Åß„Åç„Çã„ÅãÔºü„Äë\n",
            "name: ÊÇ™È≠î„ÅÆËø∑ÂÆÆ\n",
            "release_date: 2024-05-25\n",
            "short_description: ÊÇ™È≠î„ÅÆËø∑ÂÆÆ„ÇíÊé¢Á¥¢„Åó„ÄÅÊÇ™È≠î„ÅÆÈÅ∫Áâ©„ÇíÂ•™Âèñ„Åô„ÇãÊó©Êäº„Åó„ÇØ„Ç§„Ç∫ÔºÅ\n",
            "Êó©Êäº„Åó„ÇØ„Ç§„Ç∫„Ç≤„Éº„É†„ÄêÊÇ™È≠î„ÅÆËø∑ÂÆÆ„Äë„Åß„Åô„ÄÇ\n",
            "2D„Ç¢„ÇØ„Ç∑„Éß„É≥„Ç≤„Éº„É†„ÄÅÊÇ™È≠î„ÅÆÔøΩÔøΩ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# --- Ë®≠ÂÆö ---\n",
        "INPUT_FILE = \"games_march2025_cleaned.csv\"  # ÂÖ•Âäõ„Éï„Ç°„Ç§„É´Âêç\n",
        "OUTPUT_FILE = \"steam_games_filtered_final.csv\" # ÊúÄÁµÇÂá∫Âäõ„Éï„Ç°„Ç§„É´Âêç\n",
        "CUTOFF_DATE = '2024-1-1' # „Åì„ÅÆÊó•‰ªò‰ª•Ââç„ÅÆË°å„ÇíÁ†¥Ê£Ñ„Åó„Åæ„Åô\n",
        "ENCODING = \"utf-8\"\n",
        "\n",
        "# üî• ÊäΩÂá∫„Åó„Åü„ÅÑÂàóÂêç„Çí„É™„Çπ„Éà„ÅßÊåáÂÆö„Åó„Å¶„Åè„Å†„Åï„ÅÑ üî•\n",
        "# „ÅÇ„Å™„Åü„ÅÆCSV„Éï„Ç°„Ç§„É´„ÅÆ„Ç´„É©„É†Âêç„Å´Âêà„Çè„Åõ„Å¶‰øÆÊ≠£„ÅåÂøÖË¶Å„Åß„Åô\n",
        "COLUMNS_TO_KEEP = [\n",
        "    'name',\n",
        "    'release_date',\n",
        "    'genres',\n",
        "    'short_description',\n",
        "    'positive',\n",
        "    'negative',\n",
        "    'reviews'\n",
        "]\n",
        "\n",
        "# --- Âá¶ÁêÜ ---\n",
        "if not os.path.exists(INPUT_FILE):\n",
        "    print(f\"‚ùå „Ç®„É©„Éº: ÂÖ•Âäõ„Éï„Ç°„Ç§„É´ '{INPUT_FILE}' „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ„Éï„Ç°„Ç§„É´„Åå„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åï„Çå„Å¶„ÅÑ„Çã„ÅãÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\")\n",
        "else:\n",
        "    print(f\"1. „Éï„Ç°„Ç§„É´ '{INPUT_FILE}' „ÇíË™≠„ÅøËæº„Åø„ÄÅÂøÖË¶Å„Å™Âàó„ÇíÊäΩÂá∫„Åó„Åæ„Åô...\")\n",
        "    try:\n",
        "        # 1. ÂøÖË¶Å„Å™Âàó„Å†„Åë„Çí„É°„É¢„É™„Å´Ë™≠„ÅøËæº„ÇÄ (usecols„Å´„Çà„Çã„É°„É¢„É™ÂäπÁéáÂåñ)\n",
        "        # 'release_date'Âàó„ÅØÂøÖ„ÅöÂê´„ÇÅ„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„Åô\n",
        "        df = pd.read_csv(INPUT_FILE, encoding=ENCODING, usecols=COLUMNS_TO_KEEP)\n",
        "\n",
        "        # 2. Êó•‰ªòÂàó„ÇídatetimeÂûã„Å´Â§âÊèõ„Åó„ÄÅ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞Ââç„ÅÆË°åÊï∞„ÇíË®òÈå≤\n",
        "        df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
        "        rows_before_filter = len(df)\n",
        "\n",
        "        # 3. „Éï„Ç£„É´„Çø„É™„É≥„Ç∞„ÇíÂÆüË°å: CUTOFF_DATE„Çà„Çä„ÇÇÊñ∞„Åó„ÅÑË°å„Çí‰øùÊåÅ\n",
        "        print(f\"2. Êó•‰ªò„Éï„Ç£„É´„Çø„Éº '{CUTOFF_DATE}' „ÇíÈÅ©Áî®„Åó„Åæ„Åô...\")\n",
        "        cutoff_datetime = pd.to_datetime(CUTOFF_DATE)\n",
        "\n",
        "        # „É™„É™„Éº„ÇπÊó•„ÅåCUTOFF_DATE„Çà„Çä„ÇÇÂ§ß„Åç„ÅÑË°å„ÇíÊäΩÂá∫\n",
        "        df_filtered = df[df['release_date'] > cutoff_datetime].copy()\n",
        "\n",
        "        # 4. Êñ∞„Åó„ÅÑ„Éï„Ç°„Ç§„É´„Å®„Åó„Å¶‰øùÂ≠ò\n",
        "        df_filtered.to_csv(OUTPUT_FILE, index=False, encoding=ENCODING)\n",
        "\n",
        "        # 5. ÁµêÊûú„ÅÆÁ¢∫Ë™ç\n",
        "        rows_after_filter = len(df_filtered)\n",
        "        final_size_mb = os.path.getsize(OUTPUT_FILE) / (1024 * 1024)\n",
        "\n",
        "        print(\"\\nüéâ Âá¶ÁêÜ„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅ\")\n",
        "        print(f\"   ÂÖÉ„ÅÆË°åÊï∞: {rows_before_filter} Ë°å\")\n",
        "        print(f\"   ÊúÄÁµÇÁöÑ„Å™Ë°åÊï∞: {rows_after_filter} Ë°å\")\n",
        "        print(f\"   Âá∫Âäõ„Éï„Ç°„Ç§„É´Âêç: '{OUTPUT_FILE}'\")\n",
        "        print(f\"   ÊúÄÁµÇ„Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫: {final_size_mb:.2f} MB\")\n",
        "\n",
        "        if final_size_mb > 10.0:\n",
        "            print(\"‚ö†Ô∏è Ê≥®ÊÑè: ÊúÄÁµÇ„Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫„Åå10MB„ÇíË∂Ö„Åà„Å¶„ÅÑ„Åæ„Åô„ÄÇRAGÂêë„Åë„Å´„Åï„Çâ„Å´Ë°åÊï∞„ÇíÂà∂Èôê„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„Åã„ÇÇ„Åó„Çå„Åæ„Åõ„Çì„ÄÇ\")\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"‚ùå „Ç®„É©„Éº: CSV„Éï„Ç°„Ç§„É´„Å´ÊåáÂÆö„Åï„Çå„ÅüÂàó '{e}' „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ`COLUMNS_TO_KEEP`„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå „Éï„Ç°„Ç§„É´Âá¶ÁêÜ‰∏≠„Å´Ëá¥ÂëΩÁöÑ„Å™„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6IlVfRN-7Th",
        "outputId": "3f0f9167-7096-4ea0-ff53-bbdae77f92d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. „Éï„Ç°„Ç§„É´ 'games_march2025_cleaned.csv' „ÇíË™≠„ÅøËæº„Åø„ÄÅÂøÖË¶Å„Å™Âàó„ÇíÊäΩÂá∫„Åó„Åæ„Åô...\n",
            "2. Êó•‰ªò„Éï„Ç£„É´„Çø„Éº '2024-1-1' „ÇíÈÅ©Áî®„Åó„Åæ„Åô...\n",
            "\n",
            "üéâ Âá¶ÁêÜ„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅ\n",
            "   ÂÖÉ„ÅÆË°åÊï∞: 89618 Ë°å\n",
            "   ÊúÄÁµÇÁöÑ„Å™Ë°åÊï∞: 21832 Ë°å\n",
            "   Âá∫Âäõ„Éï„Ç°„Ç§„É´Âêç: 'steam_games_filtered_final.csv'\n",
            "   ÊúÄÁµÇ„Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫: 6.18 MB\n"
          ]
        }
      ]
    }
  ]
}